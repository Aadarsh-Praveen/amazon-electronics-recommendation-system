# ğŸ—ï¸ System Architecture

Complete technical architecture of the Amazon Electronics Recommendation System.

---

## ğŸ“Š High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER LAYER                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Streamlit UI â”‚  â”‚  Monitoring  â”‚  â”‚  Direct API  â”‚       â”‚
â”‚  â”‚   (Cloud)    â”‚  â”‚  Dashboard   â”‚  â”‚    Calls     â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€|â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€--â”€â”€â”€â”€â”€â”˜
          â”‚                 |                 â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  FastAPI Layer â”‚
                    â”‚  (Port 8080)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                 â”‚               â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€-â–¼â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  Logging  â”‚    â”‚   Cache   â”‚    â”‚  Search   â”‚
    â”‚  (SQLite) â”‚    â”‚  (Memory) â”‚    â”‚  Engine   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                            â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”
                        â”‚                   â”‚                   â”‚
                  â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
                  â”‚   BM25    â”‚      â”‚   Dense     â”‚     â”‚  Qdrant     â”‚
                  â”‚  (Local)  â”‚      â”‚ Embeddings  â”‚     â”‚  (Cloud)    â”‚
                  â”‚  Keyword  â”‚      â”‚   (BGE)     â”‚     â”‚  Vector DB  â”‚
                  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                   â”‚                   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ Hybrid Fusion  â”‚
                                    â”‚   (Î±=0.65)     â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                                    â”‚ BGE Reranker   â”‚
                                    â”‚ (CrossEncoder) â”‚
                                    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                     Ranked Results
```

---

## ğŸ” Search Pipeline (Detailed)

### **Phase 1: Query Processing**

```python
User Query: "noise cancelling headphones"
    â†“
Text Preprocessing (lowercase, tokenize)
    â†“
Embedding Generation (BGE-small-en-v1.5, 384 dims)
    â†“
Cache Check (embedding cache)
```

---

### **Phase 2: Dual Retrieval**

**Path A: Dense Search**
```
Query Vector (384d)
    â†“
Qdrant Vector Search (cosine similarity)
    â†“
Top 50 candidates
    â†“
Normalized scores (0-1)
```

**Path B: BM25 Search**
```
Query Tokens ["noise", "cancelling", "headphones"]
    â†“
BM25 Scoring (local index)
    â†“
Top 50 candidates
    â†“
Normalized scores (0-1)
```

---

### **Phase 3: Hybrid Fusion**

```python
For each product_id:
    hybrid_score = Î± * dense_score + (1-Î±) * bm25_score
    
Where Î± = 0.65 (tuned parameter)
```

**Why Hybrid?**
- Dense search: Semantic understanding
- BM25: Exact keyword matching
- Fusion: Best of both worlds

**Performance:**
- Dense alone: NDCG@10 = 0.72
- BM25 alone: NDCG@10 = 0.68
- **Hybrid**: NDCG@10 = 0.78

---

### **Phase 4: Reranking (Optional)**

```
Top 20 hybrid candidates
    â†“
BGE Cross-Encoder (BAAI/bge-reranker-base)
    â†“
Query-document pair scoring
    â†“
Combined Score:
    final = 0.70 * rerank_score 
          + 0.20 * sentiment_score 
          + 0.10 * popularity_score
    â†“
Top K results
```

**Performance Impact:**
- Hybrid alone: NDCG@10 = 0.78
- **With reranker**: NDCG@10 = 0.854 (+9.5%)

---

## ğŸ—„ï¸ Data Storage Architecture

### **Vector Database (Qdrant Cloud)**

**Schema:**
```python
{
    "id": 12345,  # Numeric ID
    "vector": [0.234, -0.123, ...],  # 384 dimensions
    "payload": {
        "product_id": "B00ABC123",
        "title": "Product Title",
        "brand": "Brand Name",
        "price": 49.99,
        "avg_rating": 4.5,
        "review_count": 1247,
        "sentiment_score": 0.85,
        "abstracted_summary": "Summary text...",
        "aspects": [
            {"aspect": "sound_quality", "sentiment": "positive", "score": 0.88}
        ]
    }
}
```

**Collection:** `amazon-products`  
**Vectors:** 31,100  
**Dimension:** 384  
**Distance:** Cosine  

---

### **BM25 Index (Local Cache)**

**Structure:**
```python
{
    "bm25": BM25Okapi object,
    "corpus": [
        ["token1", "token2", ...],  # Product 1
        ["token3", "token4", ...]   # Product 2
    ],
    "product_ids": ["B00ABC123", "B00DEF456", ...]
}
```

**File:** `cache/bm25_index.pkl` (122 MB)  
**Location:** Google Cloud Storage â†’ Downloaded to local cache  

---

### **Product ID Mapping (Local Cache)**

**Purpose:** Map string product IDs â†’ numeric Qdrant IDs

```python
{
    "B00ABC123": 0,
    "B00DEF456": 1,
    "B00GHI789": 2,
    ...
}
```

**File:** `cache/product_id_mapping.pkl` (486 KB)  
**Location:** Google Cloud Storage  

---

## ğŸ”„ Caching Strategy

### **Multi-Level Cache**

```
Request
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L1: Embedding Cache     â”‚  â† 1000 entries
â”‚  (query â†’ vector)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Miss
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  L2: Dense Cache     â”‚  â† 1000 entries
    â”‚  (query â†’ results)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ Miss
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  L3: BM25 Cache  â”‚  â† 1000 entries
        â”‚  (query â†’ scores)â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Miss
            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ L4: Hybrid    â”‚  â† 1000 entries
            â”‚ (final cache) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Cache Eviction:** LRU (Least Recently Used)  
**Max Size:** 1000 entries per layer  

---

## ğŸ§  ML Models Architecture

### **1. BGE Embeddings (FastEmbed)**

**Model:** `BAAI/bge-small-en-v1.5`  
**Size:** 320 MB  
**Dimension:** 384  
**Input:** Text (up to 512 tokens)  
**Output:** Dense vector  

**Usage:**
```python
from fastembed import TextEmbedding

embedder = TextEmbedding("BAAI/bge-small-en-v1.5")
vector = list(embedder.embed(["your query"]))[0]
```

---

### **2. BGE Reranker (Sentence Transformers)**

**Model:** `BAAI/bge-reranker-base`  
**Size:** 420 MB  
**Architecture:** Cross-encoder (query-document pairs)  
**Input:** [query, document] pairs  
**Output:** Relevance score (0-1)  

**Usage:**
```python
from sentence_transformers import CrossEncoder

reranker = CrossEncoder("BAAI/bge-reranker-base", max_length=512)
scores = reranker.predict([
    ["query", "document 1"],
    ["query", "document 2"]
])
```

---

### **3. Pegasus Summarization**

**Model:** `google/pegasus-cnn_dailymail`  
**Size:** 568 MB  
**Architecture:** Transformer encoder-decoder  
**Input:** Long review text (up to 512 tokens per chunk)  
**Output:** Abstractive summary  

**Strategy:**
1. Chunk long text into 300-token segments
2. Summarize each chunk (max 128 tokens)
3. Concatenate chunk summaries

---

### **4. RoBERTa Sentiment**

**Model:** `cardiffnlp/twitter-roberta-base-sentiment`  
**Size:** 499 MB  
**Classes:** Negative, Neutral, Positive  
**Input:** Summary text  
**Output:** Sentiment label + confidence score  

---

## ğŸ” Security Architecture

### **API Security**

```
Request
    â†“
CORS Middleware (allow all origins - development)
    â†“
Input Validation (Pydantic)
    â†“
Rate Limiting (future)
    â†“
Handler
```

**Recommendations for Production:**
- Add API key authentication
- Implement rate limiting
- Restrict CORS origins
- Use HTTPS (SSL/TLS)

---

### **Secret Management**

**Development:**
- `.env` files (not committed)

**Production (VM):**
- Environment variables in systemd service
- Or use Google Secret Manager

**Streamlit Cloud:**
- Streamlit Secrets (TOML format)

---

## ğŸ“ˆ Scalability

### **Current Capacity**
- **Products:** 31,100
- **Concurrent users:** ~10-20 (VM)
- **Queries/second:** ~2-3

### **Scaling Options**

**Horizontal Scaling:**
```
Load Balancer
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VM 1   â”‚ VM 2   â”‚ VM 3   â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
    â”‚         â”‚        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
      Qdrant Cloud
```

**Vertical Scaling:**
- Upgrade VM: e2-medium â†’ e2-standard-4
- Add more memory/CPU

---

## ğŸ”„ Data Flow

### **Indexing Pipeline**

```
Raw Reviews (6.7M)
    â†“
Preprocessing (clean, filter)
    â†“
Grouping (by product_id)
    â†“
Summarization (Pegasus + SageMaker)
    â†“
Sentiment Analysis (RoBERTa)
    â†“
Aspect Extraction (Zero-shot NLI)
    â†“
Metadata Merge
    â†“
Embedding Generation (BGE)
    â†“
Upload to Qdrant + Create BM25 Index
    â†“
Ready for Search
```

**Total Time:** ~20-24 hours (one-time)

---

### **Query Pipeline**

```
User Query
    â†“
API Request (FastAPI)
    â†“
Check Cache (4 levels)
    â†“ (miss)
Parallel Retrieval
    â”œâ”€ BM25 Search (local)
    â””â”€ Dense Search (Qdrant)
    â†“
Hybrid Fusion
    â†“
Retrieve Full Payloads (Qdrant)
    â†“
Reranking (BGE Cross-Encoder)
    â†“
Return Top-K Results
    â†“
Cache Results
    â†“
JSON Response
```

**Total Latency:** 50ms (cached) - 3s (uncached with reranker)

---

## ğŸ§© Component Interactions

### **HybridSearchEngine Class**

**Responsibilities:**
- Manage Qdrant connection
- Load BM25 index
- Generate embeddings
- Coordinate retrieval
- Apply reranking
- Maintain caches

**Key Methods:**
```python
get_embedding(query)          # Generate/cache embeddings
dense_search(query, top_k)    # Qdrant vector search
bm25_search(query, top_k)     # Local BM25 search
hybrid_search(query, top_k, Î±) # Fuse results
rerank(query, results, top_k) # CrossEncoder reranking
search(query, top_k, use_reranker) # Main entry point
```

---

## ğŸ’¾ Storage Architecture

### **Cloud Storage (GCS)**

```
gs://amazon-cache-bucket/
â””â”€â”€ cache/
    â”œâ”€â”€ bm25_index.pkl         (122 MB)
    â””â”€â”€ product_id_mapping.pkl (486 KB)
```

**Access Pattern:**
- Download on VM startup
- Cache locally for fast access

---

### **Vector Database (Qdrant Cloud)**

**Configuration:**
- Cluster: 1GB memory
- Collection: `amazon-products`
- Vectors: 31,100
- Dimension: 384
- Distance: Cosine

**Query Performance:**
- Average latency: 120ms
- 95th percentile: 200ms

---

### **Local Storage (VM)**

```
~/app/
â”œâ”€â”€ cache/
â”‚   â”œâ”€â”€ bm25_index.pkl    (downloaded from GCS)
â”‚   â””â”€â”€ product_id_mapping.pkl
â””â”€â”€ logs/
    â”œâ”€â”€ api.log           (rotating, 10MB max)
    â””â”€â”€ queries.db        (SQLite, query history)
```

---

## ğŸ”„ Deployment Architectures

### **Option 1: VM + Streamlit Cloud** (Current)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Streamlit Cloud  â”‚ (FREE)
â”‚   (UI Only)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Google Cloud VM   â”‚ ($25/mo, FREE with credits)
    â”‚ (API + Models)    â”‚
    â”‚ e2-medium         â”‚
    â”‚ 2 vCPU, 4GB RAM   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚ gRPC
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚  Qdrant  â”‚ ($25/mo)
        â”‚  Cloud   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total Cost:** $50/month (FREE for 12 months with GCP credits)

---

### **Option 2: All Cloud Run** (No Reranker)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cloud Run UI    â”‚ (Serverless, $0-2/mo)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Cloud Run API    â”‚ (Serverless, $3-5/mo)
    â”‚  (No Reranker)    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
        â”‚  Qdrant  â”‚ ($25/mo)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Total Cost:** $28-32/month  
**Limitation:** No reranker (NDCG drops to ~0.78)

---

## ğŸ§ª Model Performance Comparison

### **Retrieval Methods**

| Method | NDCG@10 | Latency | Complexity |
|--------|---------|---------|------------|
| **Dense only** | 0.720 | 150ms | Low |
| **BM25 only** | 0.680 | 90ms | Very Low |
| **Hybrid (Î±=0.65)** | 0.780 | 250ms | Medium |
| **Hybrid + Reranker** | 0.854 | 550ms | High |

### **Alpha (Î±) Tuning**

Hybrid fusion weight tested:

| Î± | Dense Weight | BM25 Weight | NDCG@10 |
|---|--------------|-------------|---------|
| 0.5 | 50% | 50% | 0.761 |
| 0.6 | 60% | 40% | 0.774 |
| **0.65** | **65%** | **35%** | **0.780** |
| 0.7 | 70% | 30% | 0.776 |
| 0.8 | 80% | 20% | 0.751 |

**Optimal:** Î± = 0.65 (slightly favor semantic search)

---

## ğŸ¯ Design Decisions

### **Why Hybrid Search?**

**Dense Search Strengths:**
- âœ… Semantic understanding
- âœ… Handles synonyms
- âœ… Cross-lingual potential

**Dense Search Weaknesses:**
- âŒ Misses exact keywords
- âŒ Slower indexing
- âŒ Requires GPU for large-scale

**BM25 Strengths:**
- âœ… Fast keyword matching
- âœ… No training required
- âœ… Interpretable scores

**BM25 Weaknesses:**
- âŒ No semantic understanding
- âŒ Fails on paraphrases
- âŒ Vocabulary mismatch issues

**Hybrid Solution:** Combine both! ğŸ¯

---

### **Why BGE Models?**

**Alternatives Considered:**
- Sentence-BERT
- MPNet
- E5 embeddings

**BGE Chosen Because:**
- âœ… SOTA performance on MTEB benchmark
- âœ… Small model size (320MB vs 1.2GB for large models)
- âœ… Fast inference
- âœ… Optimized for retrieval tasks

---

### **Why Qdrant?**

**Alternatives:**
- Pinecone (more expensive)
- Weaviate (complex setup)
- Milvus (self-hosted only)
- FAISS (no cloud option)

**Qdrant Chosen Because:**
- âœ… Generous free tier
- âœ… Managed cloud service
- âœ… Fast (gRPC protocol)
- âœ… Payload filtering
- âœ… Python-native

---

## ğŸ”¬ Technical Optimizations

### **1. Batch Embedding**

```python
# Instead of:
for query in queries:
    embed(query)

# Do:
embeddings = list(embedder.embed(queries))  # Batch processing
```

**Speedup:** 3-5x

---

### **2. Async Checkpoint Uploads**

```python
def save_checkpoint_async():
    threading.Thread(target=upload_to_s3).start()
```

**Benefit:** Don't block processing while uploading

---

### **3. Lazy Loading**

```python
@st.cache_resource
def load_model():
    return HybridSearchEngine()
```

**Benefit:** Load once, reuse across requests

---

### **4. Early Stopping in Reranker**

Only rerank top 20 hybrid candidates (not all 50)

**Speedup:** 2.5x faster reranking

---

## ğŸ“Š Resource Requirements

### **Development (Local)**
- **RAM:** 4GB minimum, 8GB recommended
- **Storage:** 500MB (code + cache)
- **CPU:** 2 cores minimum

### **Production (VM)**
- **RAM:** 4GB (e2-medium)
- **Storage:** 30GB disk
- **CPU:** 2 vCPUs
- **Network:** 1 Gbps

### **Production (Cloud Run)**
- **RAM:** 4GB
- **CPU:** 2 vCPUs
- **Timeout:** 600s
- **Concurrency:** 80 requests/instance

---

## ğŸ”® Future Improvements

### **Performance**
- [ ] Add GPU support for reranker
- [ ] Implement query result caching in Redis
- [ ] Use ONNX runtime for faster inference
- [ ] Quantize models (float16 â†’ int8)

### **Features**
- [ ] Personalized recommendations
- [ ] Filtering by price, brand, rating
- [ ] "More like this" feature
- [ ] User preference learning

### **Scalability**
- [ ] Kubernetes deployment
- [ ] Horizontal pod autoscaling
- [ ] Database sharding
- [ ] CDN for static assets

---

## ğŸ”— References

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [BGE Models](https://github.com/FlagOpen/FlagEmbedding)
- [BM25 Paper](https://en.wikipedia.org/wiki/Okapi_BM25)